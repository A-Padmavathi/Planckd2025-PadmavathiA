# -*- coding: utf-8 -*-
"""Minor Degree QML Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WW12YDG6rkhDdwX8U3SapEnhHt7Ba_0H
"""

MODE = "fast"

import sys
if MODE == "accurate":

    !pip install -q pennylane pennylane-qchem pyscf torch matplotlib scikit-learn
else:

    !pip install -q pennylane torch matplotlib scikit-learn

import time
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import torch
import torch.nn as nn
import torch.optim as optim
import pennylane as qml
from pennylane import numpy as pnp

SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)

def morse_energy(r, D_e=0.1745, r_eq=0.7414, a=1.02, E_inf=0.0):
    # D_e in Hartree; r in Angstrom; parameters chosen to resemble H2 curve
    return D_e*(1 - np.exp(-a*(r - r_eq)))**2 + E_inf

if MODE == "fast":
    print("MODE = fast: Generating Morse-potential dataset for H2 (quick).")
    # sample bond lengths from 0.2 to 3.0 Å (dense near equilibrium)
    r_all = np.concatenate([
        np.linspace(0.2,0.6,8),
        np.linspace(0.6,1.0,20),
        np.linspace(1.0,3.0,12)
    ])
    r_all = np.unique(np.round(r_all, 6))
    E_all = morse_energy(r_all)
else:
    # Accurate mode: use PennyLane qchem to compute electronic Hamiltonian energies for H2
    # Note: This block may take longer (pyscf installation, SCF, mapping, diagonalization).
    print("MODE = accurate: Attempting to compute real H2 Hamiltonian using pyscf + pennylane-qchem.")
    try:
        from pennylane.qchem import molecule, hf_state # newer versions may have helpers
        # We'll compute exact (full configuration interaction) energies for H2 at several distances
        distances = np.concatenate([np.linspace(0.2,0.6,8), np.linspace(0.6,1.0,12), np.linspace(1.0,3.0,10)])
        r_all = np.unique(np.round(distances,6))
        E_all = []
        for r in r_all:
            name = "H2"
            symbols = ["H", "H"]
            coordinates = np.array([ [0.0, 0.0, 0.0], [0.0, 0.0, r] ])
            # build a Hamiltonian using pennylane.qchem (this will call pyscf)
            mol = qml.qchem.Molecule(symbols, coordinates)
            hamiltonian, num_qubits = qml.qchem.molecular_hamiltonian(mol.molecular_hamiltonian(), mapping="jordan_wigner")
            # Instead of VQE, get exact ground-state by diagonalizing the sparse matrix
            H_mat = qml.utils.sparse_hamiltonian(hamiltonian).toarray()
            eigs = np.linalg.eigvalsh(H_mat)
            E0 = np.min(eigs)
            E_all.append(E0)
        E_all = np.array(E_all)
    except Exception as e:
        print("Accurate mode failed due to:", e)
        print("Falling back to 'fast' Morse dataset.")
        MODE = "fast"
        r_all = np.linspace(0.2, 3.0, 40)
        E_all = morse_energy(r_all)

# Shuffle and build train/test
r_all = np.array(r_all).reshape(-1,1)
E_all = np.array(E_all).reshape(-1,1)

# scale inputs and outputs
scaler_x = StandardScaler().fit(r_all)
scaler_y = StandardScaler().fit(E_all)

X = scaler_x.transform(r_all).astype(np.float32)
Y = scaler_y.transform(E_all).astype(np.float32)

X_train, X_test, Y_train, Y_test, r_train, r_test = train_test_split(
    X, Y, r_all, test_size=0.25, random_state=SEED
)

print(f"Dataset size: total={len(X)}, train={len(X_train)}, test={len(X_test)}")

X_train_t = torch.tensor(X_train)
Y_train_t = torch.tensor(Y_train)
X_test_t = torch.tensor(X_test)
Y_test_t = torch.tensor(Y_test)
# --- FINAL FIXED Quantum Model Section ---

n_qubits = 2
dev = qml.device("default.qubit", wires=n_qubits, shots=None)

def create_qnode(n_layers):
    @qml.qnode(dev, interface='torch', diff_method='backprop')
    def circuit(x, weights):
        x_val = x[0] if x.ndim > 0 else x
        for i in range(n_qubits):
            qml.RY(x_val, wires=i)
            qml.RZ(0.5 * x_val, wires=i)
        idx = 0
        for _ in range(n_layers):
            for q in range(n_qubits):
                qml.RY(weights[idx], wires=q); idx += 1
                qml.RZ(weights[idx], wires=q); idx += 1
            for q in range(n_qubits - 1):
                qml.CNOT(wires=[q, q + 1])
        return [qml.expval(qml.PauliZ(w)) for w in range(n_qubits)]
    return circuit

n_layers = 2
qnode = create_qnode(n_layers)

class QuantumRegressor(nn.Module):
    def __init__(self, n_qubits, n_layers):
        super().__init__()
        self.n_params = n_layers * n_qubits * 2
        init = 0.01 * torch.randn(self.n_params, dtype=torch.float32)
        self.weights = nn.Parameter(init)
        self.fc = nn.Linear(n_qubits, 1)

    def forward(self, x):
        batch_outputs = []
        for xi in x:
            xi = xi.view(-1)
            expvals = qnode(xi, self.weights)
            # Convert to float32 tensor (to match PyTorch)
            expvals_t = torch.stack([
                ev if isinstance(ev, torch.Tensor) else torch.tensor(ev)
                for ev in expvals
            ]).float()
            batch_outputs.append(expvals_t)
        batch_tensor = torch.stack(batch_outputs).float()  # [batch, n_qubits]
        out = self.fc(batch_tensor)
        return out

def train_model(model, X_train, Y_train, X_test, Y_test, epochs=200, lr=0.01, verbose=True):
    model.train()
    opt = optim.Adam(model.parameters(), lr=lr)
    loss_fn = nn.MSELoss()
    losses = []
    t0 = time.time()
    for ep in range(1, epochs+1):
        opt.zero_grad()
        preds = model(X_train)
        loss = loss_fn(preds, Y_train)
        loss.backward()
        opt.step()
        losses.append(loss.item())
        if verbose and (ep % max(1, epochs//5) == 0 or ep==1):
            print(f"Epoch {ep}/{epochs} - train loss: {loss.item():.6f}")
    elapsed = time.time() - t0
    model.eval()
    with torch.no_grad():
        pred_test = model(X_test).detach().numpy()
    test_mse = mean_squared_error(Y_test, pred_test)
    if verbose:
        print(f"Training finished in {elapsed:.2f}s. Test MSE (scaled): {test_mse:.6f}")
    return model, losses, test_mse, pred_test

# Instantiate models
quantum_model = QuantumRegressor(n_qubits=n_qubits, n_layers=n_layers)
classical_model = ClassicalMLP(in_dim=1, hidden=32)

# Training hyperparams tuned for speed
EPOCHS_Q = 150   # keep small for quick run
EPOCHS_C = 300
LR_Q = 0.02
LR_C = 0.01

print("\nTraining Classical MLP (fast)...")
classical_model, losses_c, mse_c, pred_c_scaled = train_model(classical_model, X_train_t, Y_train_t, X_test_t, Y_test_t, epochs=EPOCHS_C, lr=LR_C, verbose=False)
print(f"Classical Test MSE (scaled): {mse_c:.6f}")

print("\nTraining Quantum Regresser (fast)...")
quantum_model, losses_q, mse_q, pred_q_scaled = train_model(quantum_model, X_train_t, Y_train_t, X_test_t, Y_test_t, epochs=EPOCHS_Q, lr=LR_Q, verbose=False)
print(f"Quantum Test MSE (scaled): {mse_q:.6f}")

# 7) Convert scaled predictions back to original units (Hartree)
pred_c = scaler_y.inverse_transform(pred_c_scaled.reshape(-1,1)).flatten()
pred_q = scaler_y.inverse_transform(pred_q_scaled.reshape(-1,1)).flatten()
Y_test_orig = scaler_y.inverse_transform(Y_test).flatten()

# 8) Print results sample and plot
print("\nPredictions (bond length Å -> energy Hartree):")
for i in range(min(8, len(r_test))):
    print(f"r={r_test[i,0]:.3f} Å | true={Y_test_orig[i]:.6f} Ha | classical={pred_c[i]:.6f} | quantum={pred_q[i]:.6f}")

# Plot: true curve + predictions
# Build smooth curve for plotting
r_plot = np.linspace(np.min(r_all), np.max(r_all), 200).reshape(-1,1)
E_plot_true = morse_energy(r_plot.flatten()) if MODE == "fast" else None
if MODE == "fast":
    plt.figure(figsize=(8,5))
    plt.plot(r_plot, E_plot_true, label="True (Morse)", linewidth=2)
    # plot dataset points
    plt.scatter(r_all, E_all, label="Dataset points")
    # plot predictions
    plt.scatter(r_test, Y_test_orig, marker='x', label="Test true")
    plt.scatter(r_test, pred_c, marker='s', label="Classical preds")
    plt.scatter(r_test, pred_q, marker='o', label="Quantum preds")
    plt.xlabel("H-H bond length (Å)")
    plt.ylabel("Energy (Hartree)")
    plt.title("H2 Energy curve (Morse toy) — True vs Classical vs Quantum")
    plt.legend()
    plt.grid(True)
    plt.show()
else:
    plt.figure(figsize=(8,5))
    plt.scatter(r_all, E_all, label="Dataset energies (accurate/pyscf)")
    plt.scatter(r_test, Y_test_orig, marker='x', label="Test true")
    plt.scatter(r_test, pred_c, marker='s', label="Classical preds")
    plt.scatter(r_test, pred_q, marker='o', label="Quantum preds")
    plt.xlabel("H-H bond length (Å)")
    plt.ylabel("Energy (Hartree)")
    plt.title("H2 Energy — True (from qchem) vs Classical vs Quantum")
    plt.legend()
    plt.grid(True)
    plt.show()

mse_c_orig = mean_squared_error(Y_test_orig, pred_c)
mse_q_orig = mean_squared_error(Y_test_orig, pred_q)
print(f"\nFinal test MSE (original units, Hartree): Classical = {mse_c_orig:.6e}, Quantum = {mse_q_orig:.6e}")

torch.save(classical_model.state_dict(), "classical_mlp_h2.pth")
torch.save(quantum_model.state_dict(), "quantum_qnn_h2.pth")
print("\nModels saved: classical_mlp_h2.pth, quantum_qnn_h2.pth")